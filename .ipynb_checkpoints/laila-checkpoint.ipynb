{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing neccessary libraries\n",
    "    - pandas will be used to communicate or load our document\n",
    "    - numpy will be used for calculations on our responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load Respondents data\n",
    "    - since our data came as csv from google forms we will use pandas read csv function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('laila.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change all spaces to underscore[for spss use]\n",
    "    -since spss doesnt allow spaces , we will replace space with underscore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save changes as a new csv for spss\n",
    "    - the file generated below will be loaded unto spss for analysis\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = df.to_csv('laila1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv('laila1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we will rename these columns so as to shorten them \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_indices = [3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]\n",
    "new_names = ['income','loyalty','tang1','tang2_','rea1','rea2','resp1','resp2',\n",
    "             'assur1','assur2','assur3','empat1','empat2','empat3','cusat1','cusat2',\n",
    "             'cusat3','cusat4','cusloy1','cusloy2','cusloy3','cusloy4','cusloy5']\n",
    "old_names = df.columns[column_indices]\n",
    "df.rename(columns=dict(zip(old_names, new_names)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lets calculate mean and standard deviation \n",
    "    These line of codes does the following \n",
    "        1. Takes the response from each section and calculates thier over all mean and standard deviation\n",
    "            - take for example (tangibility which contains two questions)\n",
    "            -all responses will be sumed up and divided by total number of occurences(hence,mean)\n",
    "            -also standard deviavtion is calculated using  np.std\n",
    "        2. although mean and standard deviation will be generated in spss as well , they will however be \n",
    "            generated individually \n",
    "            -the reason for using python code here is to put them manually in a collated table in microsoft words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tangibility_mean = np.mean((df['tang1'].append(df['tang2_'])))\n",
    "tangibility_std = np.std((df['tang1'].append(df['tang2_'])))\n",
    "Reliability_mean = np.mean((df['rea1'].append(df['rea2'])))\n",
    "Reliability_std = np.std((df['rea1'].append(df['rea2'])))\n",
    "Responsiveness_mean = np.mean((df['resp1'].append(df['resp2'])))\n",
    "Responsiveness_std = np.std((df['resp1'].append(df['resp2'])))\n",
    "Assurance_mean = np.mean((df['assur1'].append(df['assur2']).append(df['assur3'])))\n",
    "Assurance_std = np.std((df['assur1'].append(df['assur2']).append(df['assur3'])))\n",
    "Empathy_mean = np.mean((df['empat1'].append(df['empat2']).append(df['empat3'])))\n",
    "Empathy_std = np.std((df['empat1'].append(df['empat2']).append(df['empat3'])))\n",
    "customer_satis_mean = np.mean((df['cusat1'].append(df['cusat2']).append(df['cusat3']).append(df['cusat4'])))\n",
    "customer_satis_std = np.std((df['cusat1'].append(df['cusat2']).append(df['cusat3']).append(df['cusat4'])))\n",
    "customer_loyal_mean = np.mean((df['cusloy1'].append(df['cusloy2']).append(df['cusloy3']).append(df['cusloy4'].append(df['cusloy5']))))\n",
    "customer_loyal_std = np.std((df['cusloy1'].append(df['cusloy2']).append(df['cusloy3']).append(df['cusloy4'].append(df['cusloy5']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## printing the results\n",
    "    -if you check the microsoft words you will see this results in a table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean of Tangibility is 2.99 and Standard Deviation is 1.05 \n",
      "\n",
      "The Mean of Reliability is 2.89 and Standard Deviation is 1.03 \n",
      "\n",
      "The Mean of Responsiveness is 3.04 and Standard Deviation is 1.06 \n",
      "\n",
      "The Mean of Assurance is 2.97 and Standard Deviation is 1.06 \n",
      "\n",
      "The Mean of Empathy is 3.03 and Standard Deviation is 1.08 \n",
      "\n",
      "The Mean of customer Satisfaction is 3.12 and Standard Deviation is 1.05 \n",
      "\n",
      "The Mean of customer loyalty is 3.16 and Standard Deviation is 1.13\n"
     ]
    }
   ],
   "source": [
    "print(f'The Mean of Tangibility is {round(tangibility_mean,2)} and Standard Deviation is {round(tangibility_std,2)}','\\n')\n",
    "print(f'The Mean of Reliability is {round(Reliability_mean,2)} and Standard Deviation is {round(Reliability_std,2)}','\\n')\n",
    "print(f'The Mean of Responsiveness is {round(Responsiveness_mean,2)} and Standard Deviation is {round(Responsiveness_std,2)}','\\n')\n",
    "print(f'The Mean of Assurance is {round(Assurance_mean,2)} and Standard Deviation is {round(Assurance_std,2)}','\\n')\n",
    "print(f'The Mean of Empathy is {round(Empathy_mean,2)} and Standard Deviation is {round(Empathy_std,2)}','\\n')\n",
    "print(f'The Mean of customer Satisfaction is {round(customer_satis_mean,2)} and Standard Deviation is {round(customer_satis_std,2)}','\\n')\n",
    "print(f'The Mean of customer loyalty is {round(customer_loyal_mean,2)} and Standard Deviation is {round(customer_loyal_std,2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lets Create 2 new csv files that only contains mean value of each section \n",
    "    -i am doing this because finding the correlation of each section will be too big \n",
    "    - so the best way is to use the mean of each section \n",
    " ## The second is to consolidate the sevice quality sections\n",
    "     - remember one of the hypothesis was to check if service quality will lead to satisafaction\n",
    "     - so we have to join tTangibility,Reliability,Responsiveness,Assurance and Empathy together so they can be \n",
    "     analysed against customer satisfaction.\n",
    "     - customer satisfaction will be analysed against loyaltyas well ,just has statedin your hyphothesis but we      dont need to create new file for these two , they are on thier own already "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with the first part \n",
    "tang = df.loc[: , \"tang1\":\"tang2_\"]\n",
    "rea= df.loc[: , \"rea1\":\"rea2\"]\n",
    "resp = df.loc[: , \"resp1\":\"resp2\"]\n",
    "assur = df.loc[: , 'assur1': 'assur3']\n",
    "empat = df.loc[: , 'empat1': 'empat3']\n",
    "cusat = df.loc[: , 'cusat1': 'cusat4']\n",
    "cusloya = df.loc[: , 'cusloy1': 'cusloy5']\n",
    "\n",
    "df['Tangibility'] = tang.mean(axis=1)\n",
    "df['Reliability'] = rea.mean(axis=1)\n",
    "df['Responsiveness'] = resp.mean(axis=1)\n",
    "df['Assurance'] = round(assur.mean(axis=1),2)\n",
    "df['Empathy'] = round(empat.mean(axis=1),2)\n",
    "df['customer_Satisfaction'] = cusat.mean(axis=1)\n",
    "df['customer_loyalty'] = cusloya.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3.734\n",
       "1      2.832\n",
       "2      2.034\n",
       "3      3.134\n",
       "4      2.100\n",
       "       ...  \n",
       "117    2.632\n",
       "118    3.000\n",
       "119    4.434\n",
       "120    3.134\n",
       "121    3.000\n",
       "Name: service_quality, Length: 122, dtype: float64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for second part\n",
    "service_quality = df.loc[: , \"Tangibility\":\"Empathy\"]\n",
    "df['service_quality']  = service_quality.mean(axis=1)\n",
    "servqualv=df.loc[:,'service_quality']\n",
    "servqualv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As u can see below we have singularized sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tangibility</th>\n",
       "      <th>Reliability</th>\n",
       "      <th>Responsiveness</th>\n",
       "      <th>Assurance</th>\n",
       "      <th>Empathy</th>\n",
       "      <th>customer_Satisfaction</th>\n",
       "      <th>customer_loyalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.33</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tangibility  Reliability  Responsiveness  Assurance  Empathy  \\\n",
       "0            3.5          4.0             4.5       3.00     3.67   \n",
       "1            3.0          2.5             4.0       2.33     2.33   \n",
       "2            2.5          2.0             3.0       1.67     1.00   \n",
       "3            3.0          3.0             3.0       4.67     2.00   \n",
       "4            1.5          1.5             1.5       1.67     4.33   \n",
       "..           ...          ...             ...        ...      ...   \n",
       "117          3.0          2.5             3.0       2.33     2.33   \n",
       "118          3.0          3.0             3.0       3.00     3.00   \n",
       "119          5.0          5.0             3.5       3.67     5.00   \n",
       "120          3.0          4.0             3.0       3.00     2.67   \n",
       "121          3.0          3.0             3.0       3.00     3.00   \n",
       "\n",
       "     customer_Satisfaction  customer_loyalty  \n",
       "0                      3.5               3.2  \n",
       "1                      2.5               2.8  \n",
       "2                      2.0               1.8  \n",
       "3                      2.5               2.6  \n",
       "4                      2.5               1.8  \n",
       "..                     ...               ...  \n",
       "117                    3.0               2.4  \n",
       "118                    3.0               3.0  \n",
       "119                    4.0               4.4  \n",
       "120                    3.0               2.6  \n",
       "121                    3.0               3.0  \n",
       "\n",
       "[122 rows x 7 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_correlation = df.loc[: , \"Tangibility\":\"customer_loyalty\"]\n",
    "for_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## so our new file will be name \"to be used for correlation.csv\"\n",
    "    -this can be used to perform correlation , regression analysis \n",
    "    -we can also create a beatiful heatmap here in the python script showing the corraltions of each sections\n",
    "    - we can aslo create regression plots \n",
    "    - this way we can find if we have multi connilearity[which we most likely have ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1 = for_correlation.to_csv('to be used for correlation.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lets start with correlations \n",
    "    -All these will be done in spss as well , but we can get charts from here,spss will only get us tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load our new file \n",
    "df3= pd.read_csv('to be used for correlation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tangibility</th>\n",
       "      <th>Reliability</th>\n",
       "      <th>Responsiveness</th>\n",
       "      <th>Assurance</th>\n",
       "      <th>Empathy</th>\n",
       "      <th>customer_Satisfaction</th>\n",
       "      <th>customer_loyalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tangibility</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760180</td>\n",
       "      <td>0.642277</td>\n",
       "      <td>0.651717</td>\n",
       "      <td>0.633656</td>\n",
       "      <td>0.704316</td>\n",
       "      <td>0.740947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reliability</th>\n",
       "      <td>0.760180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622498</td>\n",
       "      <td>0.692124</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.733676</td>\n",
       "      <td>0.750105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Responsiveness</th>\n",
       "      <td>0.642277</td>\n",
       "      <td>0.622498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.751478</td>\n",
       "      <td>0.688800</td>\n",
       "      <td>0.768839</td>\n",
       "      <td>0.729266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assurance</th>\n",
       "      <td>0.651717</td>\n",
       "      <td>0.692124</td>\n",
       "      <td>0.751478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.739764</td>\n",
       "      <td>0.869187</td>\n",
       "      <td>0.840545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Empathy</th>\n",
       "      <td>0.633656</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.688800</td>\n",
       "      <td>0.739764</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830083</td>\n",
       "      <td>0.795576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_Satisfaction</th>\n",
       "      <td>0.704316</td>\n",
       "      <td>0.733676</td>\n",
       "      <td>0.768839</td>\n",
       "      <td>0.869187</td>\n",
       "      <td>0.830083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_loyalty</th>\n",
       "      <td>0.740947</td>\n",
       "      <td>0.750105</td>\n",
       "      <td>0.729266</td>\n",
       "      <td>0.840545</td>\n",
       "      <td>0.795576</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Tangibility  Reliability  Responsiveness  Assurance  \\\n",
       "Tangibility               1.000000     0.760180        0.642277   0.651717   \n",
       "Reliability               0.760180     1.000000        0.622498   0.692124   \n",
       "Responsiveness            0.642277     0.622498        1.000000   0.751478   \n",
       "Assurance                 0.651717     0.692124        0.751478   1.000000   \n",
       "Empathy                   0.633656     0.686022        0.688800   0.739764   \n",
       "customer_Satisfaction     0.704316     0.733676        0.768839   0.869187   \n",
       "customer_loyalty          0.740947     0.750105        0.729266   0.840545   \n",
       "\n",
       "                        Empathy  customer_Satisfaction  customer_loyalty  \n",
       "Tangibility            0.633656               0.704316          0.740947  \n",
       "Reliability            0.686022               0.733676          0.750105  \n",
       "Responsiveness         0.688800               0.768839          0.729266  \n",
       "Assurance              0.739764               0.869187          0.840545  \n",
       "Empathy                1.000000               0.830083          0.795576  \n",
       "customer_Satisfaction  0.830083               1.000000          0.897617  \n",
       "customer_loyalty       0.795576               0.897617          1.000000  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
